{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids\n",
    "random_state_grid = [251, 582, 591, 825, 189, 888, 395, 943, 616, 896]\n",
    "n_estimators_grid = [25, 50, 75, 100, 125, 150, 175, 200]\n",
    "max_depth_grid = [5, 7, 10, 12, None]\n",
    "n_features = df.shape[1] - 1\n",
    "max_features_grid = ['sqrt', 'log2', n_features//3, n_features//2]\n",
    "reg_param_grid = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Store MSE and hyperparameter combinations\n",
    "rmse_results_rf = []\n",
    "rmse_results_depth = []\n",
    "rmse_results_features = []\n",
    "rmse_results_hsrf = []\n",
    "\n",
    "mae_results_rf = []\n",
    "mae_results_depth = []\n",
    "mae_results_features = []\n",
    "mae_results_hsrf = []\n",
    "\n",
    "mad_results_rf = []\n",
    "mad_results_depth = []\n",
    "mad_results_features = []\n",
    "mad_results_hsrf = []\n",
    "\n",
    "# Run RandomForestRegressor with varying max_features\n",
    "for random_state, n_estimators in itertools.product(\n",
    "        random_state_grid, n_estimators_grid):\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                         random_state=random_state, n_jobs=16, max_features=n_features//3)\n",
    "\n",
    "    predictions_rf = []\n",
    "    actual_values_rf = []\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=30,  gap=0)\n",
    "\n",
    "    for train_index, test_index in tscv.split(df):\n",
    "        train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "        X_train, y_train = train.drop(columns=['CPIAUCSL']), train['CPIAUCSL']\n",
    "        X_test, y_test = test.drop(columns=['CPIAUCSL']), test['CPIAUCSL']\n",
    "\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "        predictions_rf.extend(y_pred_rf)\n",
    "        actual_values_rf.extend(y_test)\n",
    "\n",
    "    rmse_rf = np.sqrt(mean_squared_error(actual_values_rf, predictions_rf))\n",
    "    rmse_results_rf.append([random_state, n_estimators,  rmse_rf])\n",
    "\n",
    "    mae_rf = mean_absolute_error(actual_values_rf, predictions_rf)\n",
    "    mae_results_rf.append([random_state, n_estimators,  mae_rf])\n",
    "\n",
    "    mad_rf = np.median(np.abs((np.array(actual_values_rf) - np.array(predictions_rf)) - np.median(np.array(actual_values_rf) - np.array(predictions_rf))))\n",
    "    mad_results_rf.append([random_state, n_estimators,  mad_rf])\n",
    "\n",
    "    # Print results\n",
    "    print(f'RF - Random state: {random_state}, Number of estimators: {n_estimators},  RMSE: {rmse_rf}')\n",
    "\n",
    "# Run RandomForestRegressor with varying max_depth\n",
    "for random_state, n_estimators in itertools.product(\n",
    "        random_state_grid, n_estimators_grid):\n",
    "    for max_depth in max_depth_grid:\n",
    "        rf_model_depth = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                               random_state=random_state, n_jobs=16, max_depth=max_depth, max_features=n_features//3)\n",
    "\n",
    "        predictions_depth = []\n",
    "        actual_values_depth = []\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=30,  gap=0)\n",
    "\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            X_train, y_train = train.drop(columns=['CPIAUCSL']), train['CPIAUCSL']\n",
    "            X_test, y_test = test.drop(columns=['CPIAUCSL']), test['CPIAUCSL']\n",
    "\n",
    "            rf_model_depth.fit(X_train, y_train)\n",
    "            y_pred_depth = rf_model_depth.predict(X_test)\n",
    "\n",
    "            predictions_depth.extend(y_pred_depth)\n",
    "            actual_values_depth.extend(y_test)\n",
    "\n",
    "        rmse_depth = np.sqrt(mean_squared_error(actual_values_depth, predictions_depth))\n",
    "        rmse_results_depth.append([random_state, n_estimators, max_depth,  rmse_depth])\n",
    "\n",
    "        mae_depth = mean_absolute_error(actual_values_depth, predictions_depth)\n",
    "        mae_results_depth.append([random_state, n_estimators, max_depth,  mae_depth])\n",
    "\n",
    "        mad_depth = np.median(np.abs((np.array(actual_values_depth) - np.array(predictions_depth)) - np.median(np.array(actual_values_depth) - np.array(predictions_depth))))\n",
    "        mad_results_depth.append([random_state, n_estimators, max_depth,  mad_depth])\n",
    "\n",
    "        # Print results\n",
    "        print(f'RF Depth - Random state: {random_state}, Number of estimators: {n_estimators}, Max depth: {max_depth},  RMSE: {rmse_depth}')\n",
    "\n",
    "# Run RandomForestRegressor with varying max_features\n",
    "for random_state, n_estimators in itertools.product(\n",
    "        random_state_grid, n_estimators_grid):\n",
    "    for max_features in max_features_grid:\n",
    "        rf_model_features = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                                  random_state=random_state, n_jobs=16, max_features=max_features)\n",
    "\n",
    "        predictions_features = []\n",
    "        actual_values_features = []\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=30,  gap=0)\n",
    "\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            X_train, y_train = train.drop(columns=['CPIAUCSL']), train['CPIAUCSL']\n",
    "            X_test, y_test = test.drop(columns=['CPIAUCSL']), test['CPIAUCSL']\n",
    "\n",
    "            rf_model_features.fit(X_train, y_train)\n",
    "            y_pred_features = rf_model_features.predict(X_test)\n",
    "\n",
    "            predictions_features.extend(y_pred_features)\n",
    "            actual_values_features.extend(y_test)\n",
    "\n",
    "        rmse_features = np.sqrt(mean_squared_error(actual_values_features, predictions_features))\n",
    "        rmse_results_features.append([random_state, n_estimators, max_features, rmse_features])\n",
    "\n",
    "        mae_features = mean_absolute_error(actual_values_features, predictions_features)\n",
    "        mae_results_features.append([random_state, n_estimators, max_features, mae_features])\n",
    "\n",
    "        mad_features = np.median(np.abs((np.array(actual_values_features) - np.array(predictions_features)) - np.median(np.array(actual_values_features) - np.array(predictions_features))))\n",
    "        mad_results_features.append([random_state, n_estimators, max_features, mad_features])\n",
    "\n",
    "        # Print results\n",
    "        print(f'RF Features - Random state: {random_state}, Number of estimators: {n_estimators}, Max features: {max_features}, RMSE: {rmse_features}')\n",
    "\n",
    "# Run HSTreeRegressor with varying reg_param\n",
    "for random_state, n_estimators in itertools.product(\n",
    "        random_state_grid, n_estimators_grid):\n",
    "    for reg_param in reg_param_grid:\n",
    "        rf_model_hsrf = HSTreeRegressor(estimator_=RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                                                        random_state=random_state, n_jobs=16, max_features=n_features//3),\n",
    "                                       reg_param=reg_param, shrinkage_scheme_='node_based')\n",
    "\n",
    "        predictions_hsrf = []\n",
    "        actual_values_hsrf = []\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=30,  gap=0)\n",
    "\n",
    "        for train_index, test_index in tscv.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            X_train, y_train = train.drop(columns=['CPIAUCSL']), train['CPIAUCSL']\n",
    "            X_test, y_test = test.drop(columns=['CPIAUCSL']), test['CPIAUCSL']\n",
    "\n",
    "            rf_model_hsrf.fit(X_train, y_train)\n",
    "            y_pred_hsrf = rf_model_hsrf.predict(X_test)\n",
    "\n",
    "            predictions_hsrf.extend(y_pred_hsrf)\n",
    "            actual_values_hsrf.extend(y_test)\n",
    "\n",
    "        rmse_hsrf = np.sqrt(mean_squared_error(actual_values_hsrf, predictions_hsrf))\n",
    "        rmse_results_hsrf.append([random_state, n_estimators,  reg_param, rmse_hsrf])\n",
    "\n",
    "        mae_hsrf = mean_absolute_error(actual_values_hsrf, predictions_hsrf)\n",
    "        mae_results_hsrf.append([random_state, n_estimators,  reg_param, mae_hsrf])\n",
    "\n",
    "        # Print results\n",
    "        print(f'HSRF - Random state: {random_state}, Number of estimators: {n_estimators},  Reg param: {reg_param}, RMSE: {rmse_hsrf}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_values_rf = pd.DataFrame(rmse_results_rf, columns=['random_state', 'n_estimators', 'rmse_rf'])\n",
    "rmse_values_depth = pd.DataFrame(rmse_results_depth, columns=['random_state', 'n_estimators', 'max_depth', 'rmse_depth'])\n",
    "rmse_values_features = pd.DataFrame(rmse_results_features, columns=['random_state', 'n_estimators', 'max_features', 'rmse_features'])\n",
    "rmse_values_hsrf = pd.DataFrame(rmse_results_hsrf, columns=['random_state', 'n_estimators', 'reg_param', 'rmse_hsrf'])\n",
    "\n",
    "mae_values_rf = pd.DataFrame(mae_results_rf, columns=['random_state', 'n_estimators', 'mae_rf'])\n",
    "mae_values_depth = pd.DataFrame(mae_results_depth, columns=['random_state', 'n_estimators', 'max_depth', 'mae_depth'])\n",
    "mae_values_features = pd.DataFrame(mae_results_features, columns=['random_state', 'n_estimators', 'max_features', 'mae_features'])\n",
    "mae_values_hsrf = pd.DataFrame(mae_results_hsrf, columns=['random_state', 'n_estimators', 'reg_param', 'mae_hsrf'])\n",
    "\n",
    "mad_values_rf = pd.DataFrame(mad_results_rf, columns=['random_state', 'n_estimators', 'mad_rf'])\n",
    "mad_values_depth = pd.DataFrame(mad_results_depth, columns=['random_state', 'n_estimators', 'max_depth', 'mad_depth'])\n",
    "mad_values_features = pd.DataFrame(mad_results_features, columns=['random_state', 'n_estimators', 'max_features', 'mad_features'])\n",
    "\n",
    "# store to csv\n",
    "rmse_values_rf.to_csv('rmse_values_rf.csv')\n",
    "rmse_values_depth.to_csv('rmse_values_depth.csv')\n",
    "rmse_values_features.to_csv('rmse_values_features.csv')\n",
    "rmse_values_hsrf.to_csv('rmse_values_hsrf.csv')\n",
    "\n",
    "mae_values_rf.to_csv('mae_values_rf.csv')\n",
    "mae_values_depth.to_csv('mae_values_depth.csv')\n",
    "mae_values_features.to_csv('mae_values_features.csv')\n",
    "mae_values_hsrf.to_csv('mae_values_hsrf.csv')\n",
    "\n",
    "mad_values_rf.to_csv('mad_values_rf.csv')\n",
    "mad_values_depth.to_csv('mad_values_depth.csv')\n",
    "mad_values_features.to_csv('mad_values_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading RMSE values\n",
    "rmse_values_rf = pd.read_csv('rmse_values_rf.csv')\n",
    "rmse_values_depth = pd.read_csv('rmse_values_depth.csv')\n",
    "rmse_values_features = pd.read_csv('rmse_values_features.csv')\n",
    "rmse_values_hsrf = pd.read_csv('rmse_values_hsrf.csv')\n",
    "\n",
    "# Reading MAE values\n",
    "mae_values_rf = pd.read_csv('mae_values_rf.csv')\n",
    "mae_values_depth = pd.read_csv('mae_values_depth.csv')\n",
    "mae_values_features = pd.read_csv('mae_values_features.csv')\n",
    "mae_values_hsrf = pd.read_csv('mae_values_hsrf.csv')\n",
    "\n",
    "# Reading MAD values\n",
    "mad_values_rf = pd.read_csv('mad_values_rf.csv')\n",
    "mad_values_depth = pd.read_csv('mad_values_depth.csv')\n",
    "mad_values_features = pd.read_csv('mad_values_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the values of max_depth without an input with 'None'\n",
    "rmse_values_depth['max_depth'].fillna('None', inplace=True)\n",
    "\n",
    "\n",
    "# Compute the mean RMSE by max_depth and n_estimators\n",
    "mean_rmse_depth_n_estimators = rmse_values_depth.groupby(['max_depth', 'n_estimators'])['rmse_depth'].mean()\n",
    "sem_rmse_depth_n_estimators = rmse_values_depth.groupby(['max_depth', 'n_estimators'])['rmse_depth'].sem()\n",
    "\n",
    "# for each n_estimators, give the lowest mean RMSE by max_depth\n",
    "min_rmse_depth_values = mean_rmse_depth_n_estimators.groupby('n_estimators').min()\n",
    "\n",
    "idxmin_rmse_depth_values = mean_rmse_depth_n_estimators.groupby('n_estimators').idxmin()\n",
    "\n",
    "sem_rmse_depth_n_estimators = sem_rmse_depth_n_estimators.loc[idxmin_rmse_depth_values]\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean RMSE by max_features\n",
    "rmse_by_features = rmse_values_features.groupby('max_features')['rmse_features'].mean()\n",
    "rmse_min_features = rmse_by_features.idxmin()\n",
    "\n",
    "# Compute the mean RMSE by reg_param\n",
    "rmse_by_reg_param = rmse_values_hsrf.groupby('reg_param')['rmse_hsrf'].mean()\n",
    "rmse_min_reg_param = rmse_by_reg_param.idxmin()\n",
    "\n",
    "# Compute mean RMSE by n_estimators\n",
    "mean_rmse_rf = rmse_values_rf.groupby('n_estimators')['rmse_rf'].mean()\n",
    "\n",
    "# Compute mean RMSE by n_estimators for max_depth = rmse_min_depth\n",
    "mean_rmse_depth = min_rmse_depth_values\n",
    "\n",
    "# Compute mean RMSE by n_estimators for max_features = rmse_min_features\n",
    "mean_rmse_features = rmse_values_features.loc[rmse_values_features['max_features'] == rmse_min_features].groupby('n_estimators')['rmse_features'].mean()\n",
    "\n",
    "# Compute mean RMSE by n_estimators for reg_param = rmse_min_reg_param\n",
    "mean_rmse_hsrf = rmse_values_hsrf.loc[rmse_values_hsrf['reg_param'] == rmse_min_reg_param].groupby('n_estimators')['rmse_hsrf'].mean()\n",
    "\n",
    "# Compute standard error of the mean RMSE by n_estimators\n",
    "sem_rmse_rf = rmse_values_rf.groupby('n_estimators')['rmse_rf'].sem()\n",
    "\n",
    "# Compute standard error of the mean RMSE by n_estimators for max_depth = rmse_min_depth\n",
    "sem_rmse_depth = sem_rmse_depth_n_estimators\n",
    "\n",
    "# Compute standard error of the mean RMSE by n_estimators for max_features = rmse_min_features\n",
    "sem_rmse_features = rmse_values_features.loc[rmse_values_features['max_features'] == rmse_min_features].groupby('n_estimators')['rmse_features'].sem()\n",
    "\n",
    "# Compute standard error of the mean RMSE by n_estimators for reg_param = rmse_min_reg_param\n",
    "sem_rmse_hsrf = rmse_values_hsrf.loc[rmse_values_hsrf['reg_param'] == rmse_min_reg_param].groupby('n_estimators')['rmse_hsrf'].sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean RMSE by n_estimators\n",
    "# Create error bars using standard error of the mean\n",
    "\n",
    "plt.errorbar(x=mean_rmse_rf.index, y=mean_rmse_rf, yerr=sem_rmse_rf, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0, label='RF')\n",
    "plt.errorbar(x=mean_rmse_hsrf.index, y=mean_rmse_hsrf, yerr=sem_rmse_hsrf, fmt='o', color='red', ecolor='lightgray', elinewidth=3, capsize=0, label='HSRF')\n",
    "plt.errorbar(x=mean_rmse_depth.index, y=mean_rmse_depth, yerr=sem_rmse_depth, fmt='o', color='blue', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - depth')\n",
    "plt.errorbar(x=mean_rmse_features.index, y=mean_rmse_features, yerr=sem_rmse_features, fmt='o', color='green', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - features')\n",
    "\n",
    "# Adding lines between the dots\n",
    "plt.plot(mean_rmse_rf.index, mean_rmse_rf, color='black', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_rmse_hsrf.index, mean_rmse_hsrf, color='red', linestyle='dotted', linewidth=2)\n",
    "plt.plot(mean_rmse_depth.index, mean_rmse_depth, color='blue', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_rmse_features.index, mean_rmse_features, color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the values of max_depth without an input with 'None'\n",
    "mae_values_depth['max_depth'].fillna('None', inplace=True)\n",
    "\n",
    "# Compute the mean MAE by max_depth and n_estimators\n",
    "mean_mae_depth_n_estimators = mae_values_depth.groupby(['max_depth', 'n_estimators'])['mae_depth'].mean()\n",
    "sem_mae_depth_n_estimators = mae_values_depth.groupby(['max_depth', 'n_estimators'])['mae_depth'].sem()\n",
    "\n",
    "# for each n_estimators, give the lowest mean MAE by max_depth\n",
    "min_mae_depth_values = mean_mae_depth_n_estimators.groupby('n_estimators').min()\n",
    "\n",
    "idxmin_mae_depth_values = mean_mae_depth_n_estimators.groupby('n_estimators').idxmin()\n",
    "\n",
    "sem_mae_depth_n_estimators = sem_mae_depth_n_estimators.loc[idxmin_mae_depth_values]\n",
    "\n",
    "# Compute the mean MAE by max_features\n",
    "mae_by_features = mae_values_features.groupby('max_features')['mae_features'].mean()\n",
    "mae_min_features = mae_by_features.idxmin()\n",
    "\n",
    "# Compute the mean MAE by reg_param\n",
    "mae_by_reg_param = mae_values_hsrf.groupby('reg_param')['mae_hsrf'].mean()\n",
    "mae_min_reg_param = mae_by_reg_param.idxmin()\n",
    "\n",
    "# Compute mean MAE by n_estimators\n",
    "mean_mae_rf = mae_values_rf.groupby('n_estimators')['mae_rf'].mean()\n",
    "\n",
    "# Compute mean MAE by n_estimators for max_depth = mae_min_depth\n",
    "mean_mae_depth = min_mae_depth_values\n",
    "\n",
    "# Compute mean MAE by n_estimators for max_features = mae_min_features\n",
    "mean_mae_features = mae_values_features.loc[mae_values_features['max_features'] == mae_min_features].groupby('n_estimators')['mae_features'].mean()\n",
    "\n",
    "# Compute mean MAE by n_estimators for reg_param = mae_min_reg_param\n",
    "mean_mae_hsrf = mae_values_hsrf.loc[mae_values_hsrf['reg_param'] == mae_min_reg_param].groupby('n_estimators')['mae_hsrf'].mean()\n",
    "\n",
    "# Compute standard error of the mean MAE by n_estimators\n",
    "sem_mae_rf = mae_values_rf.groupby('n_estimators')['mae_rf'].sem()\n",
    "\n",
    "# Compute standard error of the mean MAE by n_estimators for max_depth = mae_min_depth\n",
    "sem_mae_depth = sem_mae_depth_n_estimators\n",
    "\n",
    "# Compute standard error of the mean MAE by n_estimators for max_features = mae_min_features\n",
    "sem_mae_features = mae_values_features.loc[mae_values_features['max_features'] == mae_min_features].groupby('n_estimators')['mae_features'].sem()\n",
    "\n",
    "# Compute standard error of the mean MAE by n_estimators for reg_param = mae_min_reg_param\n",
    "sem_mae_hsrf = mae_values_hsrf.loc[mae_values_hsrf['reg_param'] == mae_min_reg_param].groupby('n_estimators')['mae_hsrf'].sem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean MAE by n_estimators\n",
    "# Create error bars using standard error of the mean\n",
    "\n",
    "plt.errorbar(x=mean_mae_rf.index, y=mean_mae_rf, yerr=sem_mae_rf, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0, label='RF')\n",
    "plt.errorbar(x=mean_mae_hsrf.index, y=mean_mae_hsrf, yerr=sem_mae_hsrf, fmt='o', color='red', ecolor='lightgray', elinewidth=3, capsize=0, label='HSRF')\n",
    "plt.errorbar(x=mean_mae_depth.index, y=mean_mae_depth, yerr=sem_mae_depth, fmt='o', color='blue', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - depth')\n",
    "plt.errorbar(x=mean_mae_features.index, y=mean_mae_features, yerr=sem_mae_features, fmt='o', color='green', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - features')\n",
    "\n",
    "# Adding lines between the dots\n",
    "plt.plot(mean_mae_rf.index, mean_mae_rf, color='black', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_mae_hsrf.index, mean_mae_hsrf, color='red', linestyle='dotted', linewidth=2)\n",
    "plt.plot(mean_mae_depth.index, mean_mae_depth, color='blue', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_mae_features.index, mean_mae_features, color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_values_depth['max_depth'].fillna('None', inplace=True)\n",
    "\n",
    "# Compute the mean MAD by max_depth and n_estimators\n",
    "mean_mad_depth_n_estimators = mad_values_depth.groupby(['max_depth', 'n_estimators'])['mad_depth'].mean()\n",
    "sem_mad_depth_n_estimators = mad_values_depth.groupby(['max_depth', 'n_estimators'])['mad_depth'].sem()\n",
    "\n",
    "# for each n_estimators, give the lowest mean MAD by max_depth\n",
    "min_mad_depth_values = mean_mad_depth_n_estimators.groupby('n_estimators').min()\n",
    "\n",
    "idxmin_mad_depth_values = mean_mad_depth_n_estimators.groupby('n_estimators').idxmin()\n",
    "\n",
    "sem_mad_depth_n_estimators = sem_mad_depth_n_estimators.loc[idxmin_mad_depth_values]\n",
    "\n",
    "\n",
    "# Compute the mean MAD by max_features\n",
    "mad_by_features = mad_values_features.groupby('max_features')['mad_features'].mean()\n",
    "mad_min_features = mad_by_features.idxmin()\n",
    "\n",
    "\n",
    "\n",
    "# Compute mean MAD by n_estimators\n",
    "mean_mad_rf = mad_values_rf.groupby('n_estimators')['mad_rf'].mean()\n",
    "\n",
    "# Compute mean MAD by n_estimators for max_depth = mad_min_depth\n",
    "mean_mad_depth = min_mad_depth_values\n",
    "\n",
    "# Compute mean MAD by n_estimators for max_features = mad_min_features\n",
    "mean_mad_features = mad_values_features.loc[mad_values_features['max_features'] == mad_min_features].groupby('n_estimators')['mad_features'].mean()\n",
    "\n",
    "\n",
    "# Compute standard error of the mean MAD by n_estimators\n",
    "sem_mad_rf = mad_values_rf.groupby('n_estimators')['mad_rf'].sem()\n",
    "\n",
    "# Compute standard error of the mean MAD by n_estimators for max_depth = mad_min_depth\n",
    "sem_mad_depth = sem_mad_depth_n_estimators\n",
    "\n",
    "# Compute standard error of the mean MAD by n_estimators for max_features = mad_min_features\n",
    "sem_mad_features = mad_values_features.loc[mad_values_features['max_features'] == mad_min_features].groupby('n_estimators')['mad_features'].sem()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x=mean_mad_rf.index, y=mean_mad_rf, yerr=sem_mad_rf, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0, label='RF')\n",
    "plt.errorbar(x=mean_mad_rf.index, y=mean_mad_rf, yerr=sem_mad_rf, fmt='o', color='red', ecolor='lightgray', elinewidth=3, capsize=0, label='HSRF')\n",
    "plt.errorbar(x=mean_mad_depth.index, y=mean_mad_depth, yerr=sem_mad_depth, fmt='o', color='blue', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - depth')\n",
    "plt.errorbar(x=mean_mad_features.index, y=mean_mad_features, yerr=sem_mad_features, fmt='o', color='green', ecolor='lightgray', elinewidth=3, capsize=0, label='RF - features')\n",
    "\n",
    "# Adding lines between the dots\n",
    "plt.plot(mean_mad_rf.index, mean_mad_rf, color='black', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_mad_rf.index, mean_mad_rf, color='red', linestyle='dotted', linewidth=2)\n",
    "plt.plot(mean_mad_depth.index, mean_mad_depth, color='blue', linestyle='--', linewidth=2)\n",
    "plt.plot(mean_mad_features.index, mean_mad_features, color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('MAD')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
